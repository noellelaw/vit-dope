{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A1L8mc_SoUB",
        "outputId": "08fc6b39-92b1-4abb-cd37-599b65369063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Connect to google drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install needed repositories\n",
        "!pip install mmcv-full==v1.3.9 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTDF_q6aS1HY",
        "outputId": "aaf85695-6661-400a-e6bc-b3108a15e349"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
            "Collecting mmcv-full==v1.3.9\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.3.9-cp38-cp38-manylinux1_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 33.1 MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv-full==v1.3.9) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full==v1.3.9) (7.1.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full==v1.3.9) (4.6.0.66)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full==v1.3.9) (6.0)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.3.9 yapf-0.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone ViTDope\n",
        "%cd /content/\n",
        "! git clone https://github.com/noellelaw/vit-dope\n",
        "%cd /content/vit-dope\n",
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syPZ0NT_yVOw",
        "outputId": "57cd205a-f047-4f46-f0d8-c92e5850cd91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'vit-dope'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 84 (delta 23), reused 69 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n",
            "/content/vit-dope\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chumpy\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting json_tricks\n",
            "  Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Collecting munkres\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (1.7.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (0.14.0+cu116)\n",
            "Collecting xtcocotools>=1.8\n",
            "  Downloading xtcocotools-1.12-cp38-cp38-manylinux1_x86_64.whl (314 kB)\n",
            "\u001b[K     |████████████████████████████████| 314 kB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from xtcocotools>=1.8->-r requirements.txt (line 10)) (1.21.6)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.8/dist-packages (from xtcocotools>=1.8->-r requirements.txt (line 10)) (0.29.32)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.8/dist-packages (from xtcocotools>=1.8->-r requirements.txt (line 10)) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->-r requirements.txt (line 9)) (1.13.0+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->-r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (1.24.3)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58286 sha256=4313e75adcfd94be85a94beff0425ab15f39f7f91ec65525622ec3ba3ed07e16\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/a2/b8/b8aeeeaeb01b5002085156add1aed832f2fb03e79d0f22dfed\n",
            "Successfully built chumpy\n",
            "Installing collected packages: xtcocotools, munkres, json-tricks, dataclasses, chumpy\n",
            "Successfully installed chumpy-0.70 dataclasses-0.6 json-tricks-3.16.1 munkres-1.1.4 xtcocotools-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install timm and einops\n",
        "! pip install timm==0.4.9 einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3p-ZonmyYoo",
        "outputId": "d3b4281c-6fa9-49f1-e3fb-185fb1cf5ec4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.4.9\n",
            "  Downloading timm-0.4.9-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 36.7 MB/s \n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 627 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm==0.4.9) (0.14.0+cu116)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.8/dist-packages (from timm==0.4.9) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->timm==0.4.9) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (1.24.3)\n",
            "Installing collected packages: timm, einops\n",
            "Successfully installed einops-0.6.0 timm-0.4.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import copy\n",
        "import os\n",
        "import os.path as osp\n",
        "from os.path import exists\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import json\n",
        "import datetime\n",
        "import glob\n",
        "import cv2\n",
        "import colorsys\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "from torch.distributions import MultivariateNormal as MVN\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageEnhance\n",
        "\n",
        "from math import acos\n",
        "from math import sqrt\n",
        "from math import pi  \n",
        "\n",
        "import mmcv\n",
        "from mmcv import Config, DictAction\n",
        "from mmcv.utils import get_git_hash\n",
        "from mmcv.runner import get_dist_info, init_dist, set_random_seed\n",
        "\n",
        "from collections import OrderedDict\n",
        "import tempfile\n",
        "import random\n",
        "from __future__ import print_function\n",
        "\n",
        "from models.backbones import ViT\n",
        "from ndds_dataloader import MultipleVertexJson\n",
        "from object_detector import ObjectDetector\n",
        "from core.evaluation.top_down_eval import (keypoint_pck_accuracy,\n",
        "                            keypoints_from_heatmaps,\n",
        "                            pose_pck_accuracy)\n",
        "from models.heads import TopdownHeatmapSimpleHead"
      ],
      "metadata": {
        "id": "t3RGVWFjxyyG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training hyperparameters\n",
        "DATA_PATH_TEST = '/content/drive/MyDrive/DeepLearning/test_cracker/'\n",
        "PRETRAINED = '/content/drive/MyDrive/DeepLearning/mae_pretrain_vit_base.pth'\n",
        "FROM_NET = '/content/drive/MyDrive/DeepLearning/cracker_box_train/net_epoch_39.pth'\n",
        "YCB_OBJECT = 'cracker_box'\n",
        "NOISE = 1e-5\n",
        "BRIGHTNESS = 1e-5\n",
        "CONTRAST = 1e-5\n",
        "BATCH_SIZE = 2\n",
        "IMAGE_SIZE = 256\n",
        "LEARNING_RATE = 5e-4\n",
        "EPOCHS = 60\n",
        "LOG_INTERVAL = 100\n",
        "SIGMA = 4\n",
        "OUT_FLDR = '/content/drive/MyDrive/DeepLearning/cracker_box_train'\n",
        "DATASIZE = None\n",
        "SAVE = False\n",
        "NORMAL_IMGS = None\n",
        "NB_UPDATES = None\n",
        "NAME_FILE = 'epoch'\n",
        "MAX_NORM = 1.\n",
        "NORM_TYPE = 2"
      ],
      "metadata": {
        "id": "5sDynd4WV7k_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get testing data loaders \n",
        "print (\"Loading data...\")\n",
        "transform = transforms.Compose([\n",
        "                          transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
        "                          transforms.ToTensor()])\n",
        "testingdata = None\n",
        "if not DATA_PATH_TEST == \"\":\n",
        "  testingdata = torch.utils.data.DataLoader(\n",
        "      MultipleVertexJson(\n",
        "          root = DATA_PATH_TEST,\n",
        "          objectofinterest=YCB_OBJECT,\n",
        "          keep_orientation = True,\n",
        "          noise = NOISE,\n",
        "          sigma = SIGMA,\n",
        "          data_size = DATASIZE,\n",
        "          save = SAVE,\n",
        "          transform = transform,\n",
        "          normal = NORMAL_IMGS,\n",
        "          target_transform = transforms.Compose([\n",
        "                                  transforms.Resize(IMAGE_SIZE//4),\n",
        "              ]),\n",
        "          ),\n",
        "      batch_size = BATCH_SIZE, \n",
        "      shuffle = True,\n",
        "      num_workers = 1, \n",
        "      pin_memory = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeWKnXCLxrEo",
        "outputId": "14d8cdcf-17a1-470f-fff3-8aad3ccfe4bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set up ViTDope Network\n",
        "class ViTDopeNetwork(nn.Module):\n",
        "  def __init__(\n",
        "            self,\n",
        "            pretrained=False,\n",
        "            numBeliefMap=9,\n",
        "            numAffinity=16\n",
        "            ):\n",
        "    super(ViTDopeNetwork, self).__init__()\n",
        "    # Set up backbone accordance with ViT-B\n",
        "    backbone = ViT(img_size=(256,256),\n",
        "                  patch_size=16,\n",
        "                  embed_dim=768,\n",
        "                  depth=12,\n",
        "                  num_heads=12,\n",
        "                  ratio=1,\n",
        "                  use_checkpoint=False,\n",
        "                  mlp_ratio=4,\n",
        "                  qkv_bias=True,\n",
        "                  drop_path_rate=0.3,\n",
        "    )\n",
        "    # Init ViT weights from ViT MAE trained on image net\n",
        "    if not PRETRAINED == '':\n",
        "        backbone.init_weights(pretrained=PRETRAINED)\n",
        "    # Set classical decoder head for belief maps\n",
        "    belief_head = TopdownHeatmapSimpleHead(\n",
        "        in_channels=768,\n",
        "        num_deconv_layers=2,\n",
        "        num_deconv_filters=(256, 256),\n",
        "        num_deconv_kernels=(4, 4),\n",
        "        extra=dict(final_conv_kernel=1, ),\n",
        "        out_channels=numBeliefMap,\n",
        "        loss_keypoint=dict(type='JointsMSELoss', use_target_weight=True)\n",
        "    )\n",
        "    # Set classical decoder head for affity maps\n",
        "    affinity_head = TopdownHeatmapSimpleHead(\n",
        "        in_channels=768,\n",
        "        num_deconv_layers=2,\n",
        "        num_deconv_filters=(256, 256),\n",
        "        num_deconv_kernels=(4, 4),\n",
        "        extra=dict(final_conv_kernel=1, ),\n",
        "        out_channels=numAffinity,\n",
        "        loss_keypoint=dict(type='JointsMSELoss', use_target_weight=True)\n",
        "    )\n",
        "\n",
        "    self.backbone = nn.Sequential(*[backbone])\n",
        "    self.belief_head = nn.Sequential(*[belief_head])\n",
        "    self.affinity_head = nn.Sequential(*[affinity_head])\n",
        "\n",
        "  # Forward\n",
        "  def forward(self, x):\n",
        "    backbone_out = self.backbone(x)\n",
        "    belief_out = self.belief_head(backbone_out)\n",
        "    affinity_out = self.affinity_head(backbone_out)\n",
        "    return belief_out, affinity_out\n",
        "\n"
      ],
      "metadata": {
        "id": "-LMm8y7az9Bd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set up files for testing & training progress\n",
        "\n",
        "with open (OUT_FLDR+'/loss_test.csv','w') as file: \n",
        "    file.write('epoch,batchid,loss\\n')"
      ],
      "metadata": {
        "id": "K4WlvaMY0NQ_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set up model and optimizer\n",
        "net = ViTDopeNetwork()\n",
        "net = net.to('cuda')\n",
        "# Load for inference or to resume training\n",
        "if FROM_NET!= '':\n",
        "    net.load_state_dict(torch.load(FROM_NET))"
      ],
      "metadata": {
        "id": "kQJWKwWh0jHU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run inference \n",
        "\n",
        "def _run_inference(loader,make_belief_debug_img=False,norm_belief=True, overlay_image=True):\n",
        "    net.eval()\n",
        "\n",
        "    for batch_idx, targets in enumerate(loader):\n",
        "\n",
        "        data = Variable(targets['img'].cuda())\n",
        "        output_belief, output_affinities = net(data) \n",
        "        target_belief = Variable(targets['beliefs'].cuda())        \n",
        "        target_affinity = Variable(targets['affinities'].cuda())\n",
        "\n",
        "        vertex = output_belief[-1]\n",
        "        aff = output_affinities[-1]\n",
        "\n",
        "        # Find objects from network output\n",
        "        detected_objects = ObjectDetector.find_object_poses(vertex, aff)\n",
        "\n",
        "        return detected_objects, output_belief[-1], target_belief[-1]\n"
      ],
      "metadata": {
        "id": "goyurNrZ0T7C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run inference\n",
        "\n",
        "if not DATA_PATH_TEST == \"\":\n",
        "    data, maps, targets = _run_inference(testingdata,make_belief_debug_img=True)\n",
        "\n",
        "    for i, map in enumerate(maps):\n",
        "      out = np.multiply(np.array(map.detach().cpu()), 255)\n",
        "      filename = f'/content/out_{i}.png'\n",
        "      cv2.imwrite(filename, out)\n",
        "\n",
        "    for i, target in enumerate(targets):\n",
        "      out = np.multiply(np.array(target.detach().cpu()), 255)\n",
        "      filename = f'/content/target_{i}.png'\n",
        "      cv2.imwrite(filename, out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6_8s5C30sKI",
        "outputId": "c26c2980-1d63-4362-d4bd-b005d0c4d211"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    }
  ]
}