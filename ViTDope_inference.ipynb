{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A1L8mc_SoUB",
        "outputId": "76db94a8-be28-4d91-f91f-e5d4993ae122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Connect to google drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install needed repositories\n",
        "!pip install mmcv-full==v1.3.9 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTDF_q6aS1HY",
        "outputId": "a4104730-48bd-46a5-e3a7-b8dce106668a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
            "Collecting mmcv-full==v1.3.9\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.3.9-cp38-cp38-manylinux1_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full==v1.3.9) (6.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full==v1.3.9) (7.1.2)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full==v1.3.9) (4.6.0.66)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv-full==v1.3.9) (1.21.6)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.3.9 yapf-0.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone ViTDope\n",
        "%cd /content/\n",
        "! git clone https://github.com/noellelaw/vit-dope\n",
        "%cd /content/vit-dope\n",
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syPZ0NT_yVOw",
        "outputId": "bfa0725f-82a6-49f6-c5b9-f357fa98dee0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'vit-dope'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 162 (delta 75), reused 108 (delta 37), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (162/162), 658.35 KiB | 3.94 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "/content/vit-dope\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chumpy\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting json_tricks\n",
            "  Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Collecting munkres\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (1.7.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (0.14.0+cu116)\n",
            "Collecting xtcocotools>=1.8\n",
            "  Downloading xtcocotools-1.12-cp38-cp38-manylinux1_x86_64.whl (314 kB)\n",
            "\u001b[K     |████████████████████████████████| 314 kB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.8/dist-packages (from xtcocotools>=1.8->-r requirements.txt (line 10)) (0.29.32)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.8/dist-packages (from xtcocotools>=1.8->-r requirements.txt (line 10)) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from xtcocotools>=1.8->-r requirements.txt (line 10)) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->-r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->-r requirements.txt (line 9)) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->-r requirements.txt (line 9)) (1.24.3)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58286 sha256=44ff537a203eb205bf4cbe744d0ee807e07acff0da88444775069f66ddbfff2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/a2/b8/b8aeeeaeb01b5002085156add1aed832f2fb03e79d0f22dfed\n",
            "Successfully built chumpy\n",
            "Installing collected packages: xtcocotools, munkres, json-tricks, dataclasses, chumpy\n",
            "Successfully installed chumpy-0.70 dataclasses-0.6 json-tricks-3.16.1 munkres-1.1.4 xtcocotools-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install timm and einops\n",
        "! pip install timm==0.4.9 einops\n",
        "! pip install pyrr"
      ],
      "metadata": {
        "id": "Z3p-ZonmyYoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import random\n",
        "from enum import IntEnum\n",
        "from pyrr import Quaternion\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "from torch.distributions import MultivariateNormal as MVN\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageEnhance\n",
        "\n",
        "from math import acos\n",
        "from math import sqrt\n",
        "from math import pi  \n",
        "import math\n",
        "\n",
        "from models.backbones import ViT\n",
        "from scripts.object_detector import ObjectDetector\n",
        "from models.heads import TopdownHeatmapSimpleHead"
      ],
      "metadata": {
        "id": "t3RGVWFjxyyG",
        "cellView": "form"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training hyperparameters\n",
        "YCB_OBJECT = 'cracker_box'#@param{type:'string'}\n",
        "IMG_PATH = '/content/drive/MyDrive/DeepLearning/test_cracker/kitchen_0/000074.left.jpg' #@param{type:'string'}\n",
        "FROM_NET = '/content/drive/MyDrive/DeepLearning/cracker_box_train/net_epoch_61.pth'#@param{type:'string'}\n",
        "PRETRAINED = '' #@param{type:'string'}\n",
        "IMAGE_SIZE = 256#@param{type:'integer'}"
      ],
      "metadata": {
        "id": "5sDynd4WV7k_",
        "cellView": "form"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ViTDope Network\n",
        "class ViTDopeNetwork(nn.Module):\n",
        "  def __init__(\n",
        "            self,\n",
        "            pretrained=False,\n",
        "            numBeliefMap=9,\n",
        "            numAffinity=16\n",
        "            ):\n",
        "    super(ViTDopeNetwork, self).__init__()\n",
        "    # Set up backbone accordance with ViT-B\n",
        "    backbone = ViT(img_size=(256,256),\n",
        "                  patch_size=16,\n",
        "                  embed_dim=768,\n",
        "                  depth=12,\n",
        "                  num_heads=12,\n",
        "                  ratio=1,\n",
        "                  use_checkpoint=False,\n",
        "                  mlp_ratio=4,\n",
        "                  qkv_bias=True,\n",
        "                  drop_path_rate=0.3,\n",
        "    )\n",
        "    # Init ViT weights from ViT MAE trained on image net\n",
        "    if not PRETRAINED == '':\n",
        "        backbone.init_weights(pretrained=PRETRAINED)\n",
        "    # Set classical decoder head for belief maps\n",
        "    belief_head = TopdownHeatmapSimpleHead(\n",
        "        in_channels=768,\n",
        "        num_deconv_layers=2,\n",
        "        num_deconv_filters=(256, 256),\n",
        "        num_deconv_kernels=(4, 4),\n",
        "        extra=dict(final_conv_kernel=1, ),\n",
        "        out_channels=numBeliefMap,\n",
        "        loss_keypoint=dict(type='JointsMSELoss', use_target_weight=True)\n",
        "    )\n",
        "    # Set classical decoder head for affity maps\n",
        "    affinity_head = TopdownHeatmapSimpleHead(\n",
        "        in_channels=768,\n",
        "        num_deconv_layers=2,\n",
        "        num_deconv_filters=(256, 256),\n",
        "        num_deconv_kernels=(4, 4),\n",
        "        extra=dict(final_conv_kernel=1, ),\n",
        "        out_channels=numAffinity,\n",
        "        loss_keypoint=dict(type='JointsMSELoss', use_target_weight=True)\n",
        "    )\n",
        "\n",
        "    self.backbone = nn.Sequential(*[backbone])\n",
        "    self.belief_head = nn.Sequential(*[belief_head])\n",
        "    self.affinity_head = nn.Sequential(*[affinity_head])\n",
        "\n",
        "  # Forward\n",
        "  def forward(self, x):\n",
        "    backbone_out = self.backbone(x)\n",
        "    belief_out = self.belief_head(backbone_out)\n",
        "    affinity_out = self.affinity_head(backbone_out)\n",
        "    return belief_out, affinity_out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-LMm8y7az9Bd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualization utils\n",
        "# Adapted from https://github.com/NVlabs/Deep_Object_Pose\n",
        "def DrawLine(point1, point2, lineColor, lineWidth,draw):\n",
        "    if not point1 is None and not point2 is None:\n",
        "        cv.line(draw, point1,point2,lineColor,lineWidth)\n",
        "\n",
        "def DrawCube(points, which_color = 0, color = None, draw = None):\n",
        "    '''Draw cube with a thick solid line across the front top edge.'''\n",
        "    lineWidthForDrawing = 2\n",
        "    lineWidthThick = 8\n",
        "    lineColor1 = (255, 215, 0)  # yellow-ish\n",
        "    lineColor2 = (12, 115, 170)  # blue-ish\n",
        "    lineColor3 = (45, 195, 35)  # green-ish\n",
        "    if which_color == 3:\n",
        "        lineColor = lineColor3\n",
        "    else:\n",
        "        lineColor = lineColor1\n",
        "\n",
        "    if not color is None:\n",
        "        lineColor = color        \n",
        "\n",
        "    # draw front\n",
        "    DrawLine(points[0], points[1], lineColor, lineWidthThick, draw)\n",
        "    DrawLine(points[1], points[2], lineColor, lineWidthForDrawing, draw)\n",
        "    DrawLine(points[3], points[2], lineColor, lineWidthForDrawing, draw)\n",
        "    DrawLine(points[3], points[0], lineColor, lineWidthForDrawing, draw)\n",
        "    \n",
        "    # draw back\n",
        "    DrawLine(points[4], points[5], lineColor, lineWidthForDrawing, draw)\n",
        "    DrawLine(points[6], points[5], lineColor, lineWidthForDrawing, draw)\n",
        "    DrawLine(points[6], points[7], lineColor, lineWidthForDrawing, draw)\n",
        "    DrawLine(points[4], points[7], lineColor, lineWidthForDrawing, draw)\n",
        "    \n",
        "    # draw sides\n",
        "    DrawLine(points[0], points[4], lineColor, lineWidthForDrawing, draw)\n",
        "    DrawLine(points[7], points[3], lineColor, lineWidthForDrawing, draw)\n",
        "    DrawLine(points[5], points[1], lineColor, lineWidthForDrawing, draw)\n",
        "    DrawLine(points[2], points[6], lineColor, lineWidthForDrawing, draw)\n",
        "\n"
      ],
      "metadata": {
        "id": "HGj1DItPEdQw",
        "cellView": "form"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cuboid class\n",
        "# Taken from https://github.com/NVlabs/Deep_Object_Pose\n",
        "# TODO: Move to github\n",
        "# Related to the object's local coordinate system\n",
        "class CuboidVertexType(IntEnum):\n",
        "    FrontTopRight = 0\n",
        "    FrontTopLeft = 1\n",
        "    FrontBottomLeft = 2\n",
        "    FrontBottomRight = 3\n",
        "    RearTopRight = 4\n",
        "    RearTopLeft = 5\n",
        "    RearBottomLeft = 6\n",
        "    RearBottomRight = 7\n",
        "    Center = 8\n",
        "    TotalCornerVertexCount = 8 # Corner vertexes doesn't include the center point\n",
        "    TotalVertexCount = 9\n",
        "\n",
        "# List of the vertex indexes in each line edges of the cuboid\n",
        "CuboidLineIndexes = [\n",
        "    # Front face\n",
        "    [ CuboidVertexType.FrontTopLeft,      CuboidVertexType.FrontTopRight ],\n",
        "    [ CuboidVertexType.FrontTopRight,     CuboidVertexType.FrontBottomRight ],\n",
        "    [ CuboidVertexType.FrontBottomRight,  CuboidVertexType.FrontBottomLeft ],\n",
        "    [ CuboidVertexType.FrontBottomLeft,   CuboidVertexType.FrontTopLeft ],\n",
        "    # Back face\n",
        "    [ CuboidVertexType.RearTopLeft,       CuboidVertexType.RearTopRight ],\n",
        "    [ CuboidVertexType.RearTopRight,      CuboidVertexType.RearBottomRight ],\n",
        "    [ CuboidVertexType.RearBottomRight,   CuboidVertexType.RearBottomLeft ],\n",
        "    [ CuboidVertexType.RearBottomLeft,    CuboidVertexType.RearTopLeft ],\n",
        "    # Left face\n",
        "    [ CuboidVertexType.FrontBottomLeft,   CuboidVertexType.RearBottomLeft ],\n",
        "    [ CuboidVertexType.FrontTopLeft,      CuboidVertexType.RearTopLeft ],\n",
        "    # Right face\n",
        "    [ CuboidVertexType.FrontBottomRight,  CuboidVertexType.RearBottomRight ],\n",
        "    [ CuboidVertexType.FrontTopRight,     CuboidVertexType.RearTopRight ],\n",
        "]\n",
        "\n",
        "\n",
        "# ========================= Cuboid3d =========================\n",
        "class Cuboid3d():\n",
        "    '''This class contains a 3D cuboid.'''\n",
        "\n",
        "    # Create a box with a certain size\n",
        "    def __init__(self, size3d = [1.0, 1.0, 1.0], center_location = [0, 0, 0],\n",
        "        coord_system = None, parent_object = None):\n",
        "\n",
        "        # NOTE: This local coordinate system is similar\n",
        "        # to the intrinsic transform matrix of a 3d object\n",
        "        self.center_location = center_location\n",
        "        self.coord_system = coord_system\n",
        "        self.size3d = size3d\n",
        "        self._vertices = [0, 0, 0] * CuboidVertexType.TotalVertexCount\n",
        "\n",
        "        self.generate_vertexes()\n",
        "\n",
        "    def get_vertex(self, vertex_type):\n",
        "        \"\"\"Returns the location of a vertex.\n",
        "        Args:\n",
        "            vertex_type: enum of type CuboidVertexType\n",
        "        Returns:\n",
        "            Numpy array(3) - Location of the vertex type in the cuboid\n",
        "        \"\"\"\n",
        "        return self._vertices[vertex_type]\n",
        "\n",
        "    def get_vertices(self):\n",
        "        return self._vertices\n",
        "\n",
        "    def generate_vertexes(self):\n",
        "        width, height, depth = self.size3d\n",
        "\n",
        "        # By default just use the normal OpenCV coordinate system\n",
        "        if (self.coord_system is None):\n",
        "            cx, cy, cz = self.center_location\n",
        "            # X axis point to the right\n",
        "            right = cx + width / 2.0\n",
        "            left = cx - width / 2.0\n",
        "            # Y axis point downward\n",
        "            top = cy - height / 2.0\n",
        "            bottom = cy + height / 2.0\n",
        "            # Z axis point forward\n",
        "            front = cz + depth / 2.0\n",
        "            rear = cz - depth / 2.0\n",
        "\n",
        "            # List of 8 vertices of the box       \n",
        "            self._vertices = [\n",
        "                [right, top, front],    # Front Top Right\n",
        "                [left, top, front],     # Front Top Left\n",
        "                [left, bottom, front],  # Front Bottom Left\n",
        "                [right, bottom, front], # Front Bottom Right\n",
        "                [right, top, rear],     # Rear Top Right\n",
        "                [left, top, rear],      # Rear Top Left\n",
        "                [left, bottom, rear],   # Rear Bottom Left\n",
        "                [right, bottom, rear],  # Rear Bottom Right\n",
        "                self.center_location,   # Center\n",
        "            ]\n",
        "        else:\n",
        "            sx, sy, sz = self.size3d\n",
        "            forward = np.array(self.coord_system.forward, dtype=float) * sy * 0.5\n",
        "            up = np.array(self.coord_system.up, dtype=float) * sz * 0.5\n",
        "            right = np.array(self.coord_system.right, dtype=float) * sx * 0.5\n",
        "            center = np.array(self.center_location, dtype=float)\n",
        "            self._vertices = [\n",
        "                center + forward + up + right,      # Front Top Right\n",
        "                center + forward + up - right,      # Front Top Left\n",
        "                center + forward - up - right,      # Front Bottom Left\n",
        "                center + forward - up + right,      # Front Bottom Right\n",
        "                center - forward + up  + right,     # Rear Top Right\n",
        "                center - forward + up - right,      # Rear Top Left\n",
        "                center - forward - up - right,      # Rear Bottom Left\n",
        "                center - forward - up + right,      # Rear Bottom Right\n",
        "                self.center_location,               # Center\n",
        "            ]\n",
        "\n",
        "    def get_projected_cuboid2d(self, cuboid_transform, camera_intrinsic_matrix):\n",
        "        \"\"\"\n",
        "        Projects the cuboid into the image plane using camera intrinsics.\n",
        "        Args:\n",
        "            cuboid_transform: the world transform of the cuboid\n",
        "            camera_intrinsic_matrix: camera intrinsic matrix\n",
        "        Returns:\n",
        "            Cuboid2d - the projected cuboid points\n",
        "        \"\"\"\n",
        "\n",
        "        world_transform_matrix = cuboid_transform\n",
        "        rvec = [0, 0, 0]\n",
        "        tvec = [0, 0, 0]\n",
        "        dist_coeffs = np.zeros((4, 1))\n",
        "\n",
        "        transformed_vertices = [0, 0, 0] * CuboidVertexType.TotalVertexCount\n",
        "        for vertex_index in range(CuboidVertexType.TotalVertexCount):\n",
        "            vertex3d = self._vertices[vertex_index]\n",
        "            transformed_vertices[vertex_index] = world_transform_matrix * vertex3d\n",
        "\n",
        "        projected_vertices = cv.projectPoints(transformed_vertices, rvec, tvec, \n",
        "                                camera_intrinsic_matrix, dist_coeffs)\n",
        "\n",
        "        return Cuboid2d(projected_vertices)"
      ],
      "metadata": {
        "id": "21vzWbgUsg66",
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PnP solver class\n",
        "# Taken from https://github.com/NVlabs/Deep_Object_Pose\n",
        "# Takes in identified object points and retrieves 6-DoF object pose\n",
        "# PnP algorithm used is based on number of valid points identified\n",
        "# TODO: Move to github\n",
        "\n",
        "class CuboidPNPSolver(object):\n",
        "    \"\"\"\n",
        "    This class is used to find the 6-DoF pose of a cuboid given its projected vertices.\n",
        "    Runs perspective-n-point (PNP) algorithm.\n",
        "    \"\"\"\n",
        "\n",
        "    # Class variables\n",
        "    cv2version = cv.__version__.split('.')\n",
        "    cv2majorversion = int(cv2version[0])\n",
        "\n",
        "    def __init__(self, object_name=\"\", camera_intrinsic_matrix = None, cuboid3d = None,\n",
        "            dist_coeffs = np.zeros((4, 1))):\n",
        "        self.object_name = object_name\n",
        "        if (not camera_intrinsic_matrix is None):\n",
        "            self._camera_intrinsic_matrix = camera_intrinsic_matrix\n",
        "        else:\n",
        "            self._camera_intrinsic_matrix = np.array([\n",
        "                [0, 0, 0],\n",
        "                [0, 0, 0],\n",
        "                [0, 0, 0]\n",
        "            ])\n",
        "        self._cuboid3d = cuboid3d\n",
        "\n",
        "        self._dist_coeffs = dist_coeffs\n",
        "\n",
        "    def set_camera_intrinsic_matrix(self, new_intrinsic_matrix):\n",
        "        '''Sets the camera intrinsic matrix'''\n",
        "        self._camera_intrinsic_matrix = new_intrinsic_matrix\n",
        "\n",
        "    def set_dist_coeffs(self, dist_coeffs):\n",
        "        '''Sets the camera intrinsic matrix'''\n",
        "        self._dist_coeffs = dist_coeffs\n",
        "\n",
        "    def solve_pnp(self, cuboid2d_points, pnp_algorithm = None):\n",
        "        \"\"\"\n",
        "        Detects the rotation and traslation\n",
        "        of a cuboid object from its vertexes'\n",
        "        2D location in the image\n",
        "        \"\"\"\n",
        "\n",
        "        location = None\n",
        "        quaternion = None\n",
        "        projected_points = cuboid2d_points\n",
        "\n",
        "        cuboid3d_points = np.array(self._cuboid3d.get_vertices())\n",
        "        obj_2d_points = []\n",
        "        obj_3d_points = []\n",
        "\n",
        "        for i in range(CuboidVertexType.TotalVertexCount):\n",
        "            check_point_2d = cuboid2d_points[i]\n",
        "            # Ignore invalid points\n",
        "            if (check_point_2d is None):\n",
        "                continue\n",
        "            obj_2d_points.append(check_point_2d)\n",
        "            obj_3d_points.append(cuboid3d_points[i])\n",
        "\n",
        "        obj_2d_points = np.array(obj_2d_points, dtype=float)\n",
        "        obj_3d_points = np.array(obj_3d_points, dtype=float)\n",
        "\n",
        "        valid_point_count = len(obj_2d_points)\n",
        "        print(valid_point_count, \"valid points found\" )\n",
        "\n",
        "        # Set PNP algorithm based on OpenCV version and number of valid points\n",
        "        is_points_valid = False\n",
        "\n",
        "        if pnp_algorithm is None:\n",
        "            if CuboidPNPSolver.cv2majorversion == 2:\n",
        "                is_points_valid = True\n",
        "                pnp_algorithm = cv.CV_ITERATIVE\n",
        "            elif CuboidPNPSolver.cv2majorversion > 2:\n",
        "                if valid_point_count >= 6:\n",
        "                    is_points_valid = True\n",
        "                    pnp_algorithm = cv.SOLVEPNP_ITERATIVE\n",
        "                elif valid_point_count >= 4:\n",
        "                    is_points_valid = True\n",
        "                    pnp_algorithm = cv.SOLVEPNP_P3P\n",
        "                    # This algorithm requires EXACTLY four points, so we truncate our\n",
        "                    # data\n",
        "                    obj_3d_points = obj_3d_points[:4]\n",
        "                    obj_2d_points = obj_2d_points[:4]\n",
        "                    # Alternative algorithms:\n",
        "                    # pnp_algorithm = SOLVE_PNP_EPNP\n",
        "            else:\n",
        "                assert False, \"DOPE will not work with versions of OpenCV earlier than 2.0\"\n",
        "\n",
        "        if is_points_valid:\n",
        "            try:\n",
        "                ret, rvec, tvec = cv.solvePnP(\n",
        "                    obj_3d_points,\n",
        "                    obj_2d_points,\n",
        "                    self._camera_intrinsic_matrix,\n",
        "                    self._dist_coeffs,\n",
        "                    flags=pnp_algorithm\n",
        "                )\n",
        "            except:\n",
        "                # solvePnP will assert if there are insufficient points for the\n",
        "                # algorithm\n",
        "                print(\"cv2.solvePnP failed with an error\")\n",
        "                ret = False\n",
        "\n",
        "            if ret:\n",
        "                location = list(x[0] for x in tvec)\n",
        "                quaternion = self.convert_rvec_to_quaternion(rvec)\n",
        "\n",
        "                projected_points, _ = cv.projectPoints(cuboid3d_points, rvec, tvec, self._camera_intrinsic_matrix, self._dist_coeffs)\n",
        "                projected_points = np.squeeze(projected_points)\n",
        "\n",
        "                # If the location.Z is negative or object is behind the camera then flip both location and rotation\n",
        "                x, y, z = location\n",
        "                if z < 0:\n",
        "                    # Get the opposite location\n",
        "                    location = [-x, -y, -z]\n",
        "\n",
        "                    # Change the rotation by 180 degree\n",
        "                    rotate_angle = np.pi\n",
        "                    rotate_quaternion = Quaternion.from_axis_rotation(location, rotate_angle)\n",
        "                    quaternion = rotate_quaternion.cross(quaternion)\n",
        "\n",
        "        return location, quaternion, projected_points\n",
        "\n",
        "    def convert_rvec_to_quaternion(self, rvec):\n",
        "        '''Convert rvec (which is log quaternion) to quaternion'''\n",
        "        theta = np.sqrt(rvec[0] * rvec[0] + rvec[1] * rvec[1] + rvec[2] * rvec[2])  # in radians\n",
        "        raxis = [rvec[0] / theta, rvec[1] / theta, rvec[2] / theta]\n",
        "\n",
        "        # pyrr's Quaternion (order is XYZW), https://pyrr.readthedocs.io/en/latest/oo_api_quaternion.html\n",
        "        return Quaternion.from_axis_rotation(raxis, theta)\n",
        "\n",
        "        # Alternatively: pyquaternion\n",
        "        # return Quaternion(axis=raxis, radians=theta)  # uses OpenCV's Quaternion (order is WXYZ)\n",
        "\n",
        "    def project_points(self, rvec, tvec):\n",
        "        '''Project points from model onto image using rotation, translation'''\n",
        "        output_points, tmp = cv.projectPoints(\n",
        "            self.__object_vertex_coordinates,\n",
        "            rvec,\n",
        "            tvec,\n",
        "            self.__camera_intrinsic_matrix,\n",
        "            self.__dist_coeffs)\n",
        "\n",
        "        output_points = np.squeeze(output_points)\n",
        "        return output_points"
      ],
      "metadata": {
        "cellView": "form",
        "id": "15S7q77CtCKz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load model\n",
        "net = ViTDopeNetwork()\n",
        "net = net.to('cuda')\n",
        "# Load for inference or to resume training\n",
        "if FROM_NET!= '':\n",
        "    net.load_state_dict(torch.load(FROM_NET))"
      ],
      "metadata": {
        "id": "kQJWKwWh0jHU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Inference\n",
        "# Adapted from https://github.com/NVlabs/Deep_Object_Pose\n",
        "# Global transform for image input\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "# Camera intrisics matrix\n",
        "camera_intrinsics = np.array([\n",
        "    768.16058349609375, 0, 480,\n",
        "    0, 768.16058349609375, 270,\n",
        "    0, 0, 1\n",
        "]).reshape((3,3))\n",
        "# YCB object dimensions\n",
        "dimensions = {\n",
        "    \"cracker\": [16.403600692749023,21.343700408935547,7.179999828338623]\n",
        "    }\n",
        "\n",
        "# Run inference\n",
        "def _run_inference(in_img, make_belief_debug_img=False, norm_belief=True, overlay_image=True):\n",
        "    # Put network into evaluation mode\n",
        "    net.eval()\n",
        "    # Start time for inference\n",
        "    start = time.time()\n",
        "    # Incase no image is given\n",
        "    if in_img is None:\n",
        "        return []\n",
        "\n",
        "    # Run network inference\n",
        "    image_tensor = transform(in_img)\n",
        "    image_torch = Variable(image_tensor).cuda().unsqueeze(0)\n",
        "    output_belief, output_affinities = net(image_torch) \n",
        "    # Find detected objects from network output\n",
        "    vertex = output_belief[-1]\n",
        "    aff = output_affinities[-1]\n",
        "    detected_objects = ObjectDetector.find_object_poses(vertex, aff)\n",
        "    # Set up cuboid to pass into pnp solver in accordance with object dimmensions\n",
        "    cuboid = Cuboid3d(size3d=dimensions['cracker'])\n",
        "    # Set up pnp solver\n",
        "    pnp_solver = CuboidPNPSolver('cracker_box', camera_intrinsics, cuboid)\n",
        "    # For each object identified, find the 6-DoF pose using PnP\n",
        "    for i, obj in enumerate(detected_objects):\n",
        "      points = obj['cuboid2d']\n",
        "      # Run PNP\n",
        "      location, quaternion, projected_points = pnp_solver.solve_pnp(points)\n",
        "      # Add results to detected object\n",
        "      detected_objects[i]['location'] = location\n",
        "      detected_objects[i]['quaternion'] = quaternion\n",
        "      detected_objects[i]['projected_points'] = projected_points\n",
        "    # Time inference ends\n",
        "    end = time.time()\n",
        "    print(f'Inference time: {end-start}s')\n",
        "    # Return values of interest\n",
        "    return detected_objects, vertex, image_tensor\n",
        "\n",
        "# Call _run_inference\n",
        "in_image = Image.open(IMG_PATH)\n",
        "data, maps, imgs = _run_inference(in_image,make_belief_debug_img=True)"
      ],
      "metadata": {
        "id": "goyurNrZ0T7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize projected points on image\n",
        "color = None\n",
        "# Read in input image\n",
        "in_image = cv.imread(IMG_PATH)\n",
        "in_image = cv.cvtColor(in_image, cv.COLOR_BGR2RGB)\n",
        "for obj in data:\n",
        "      points = obj['projected_points'][:8].astype('uint32')\n",
        "      # Draw all the found objects.\n",
        "      DrawCube(points, which_color=3, draw=in_image)\n",
        "# Display the image\n",
        "Image.fromarray(in_image)"
      ],
      "metadata": {
        "id": "GSx8LxGGFIL5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}